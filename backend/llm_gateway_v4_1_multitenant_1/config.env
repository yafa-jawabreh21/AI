# Provider/config as usual
LLM_PROVIDER=openai
LLM_ENDPOINT=https://api.openai.com/v1
LLM_API_KEY=sk-REPLACE_ME
LLM_MODEL=gpt-4o-mini

# === Multi-tenant keys ===
# If API_KEYS_FILE exists, multi-tenant mode is ON and X-API-KEY must be one of the listed keys.
API_KEYS_FILE=./api_keys.json

# === Global fallback (used only if multi-tenant is OFF) ===
BACKEND_API_KEY=

# === Optional per-gateway rate limiting (used if multi-tenant OFF or as a cap) ===
RATE_LIMIT_RPS=5
RATE_LIMIT_BURST=20

# === OpenTelemetry OTLP (optional) ===
# For OTLP/gRPC: e.g. http://localhost:4317
# For OTLP/HTTP: e.g. http://localhost:4318/v1/traces  (set OTEL_EXPORTER_OTLP_PROTOCOL=http/protobuf)
OTEL_EXPORTER_OTLP_ENDPOINT=
OTEL_EXPORTER_OTLP_PROTOCOL=grpc
OTEL_RESOURCE_SERVICE_NAME=llm-gateway-v4_1
OTEL_HEADERS=
